(function(e){function t(t){for(var n,i,l=t[0],r=t[1],c=t[2],u=0,b=[];u<l.length;u++)i=l[u],Object.prototype.hasOwnProperty.call(s,i)&&s[i]&&b.push(s[i][0]),s[i]=0;for(n in r)Object.prototype.hasOwnProperty.call(r,n)&&(e[n]=r[n]);d&&d(t);while(b.length)b.shift()();return o.push.apply(o,c||[]),a()}function a(){for(var e,t=0;t<o.length;t++){for(var a=o[t],n=!0,l=1;l<a.length;l++){var r=a[l];0!==s[r]&&(n=!1)}n&&(o.splice(t--,1),e=i(i.s=a[0]))}return e}var n={},s={app:0},o=[];function i(t){if(n[t])return n[t].exports;var a=n[t]={i:t,l:!1,exports:{}};return e[t].call(a.exports,a,a.exports,i),a.l=!0,a.exports}i.m=e,i.c=n,i.d=function(e,t,a){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:a})},i.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var a=Object.create(null);if(i.r(a),Object.defineProperty(a,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var n in e)i.d(a,n,function(t){return e[t]}.bind(null,n));return a},i.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return i.d(t,"a",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p="/HAA4D/";var l=window["webpackJsonp"]=window["webpackJsonp"]||[],r=l.push.bind(l);l.push=t,l=l.slice();for(var c=0;c<l.length;c++)t(l[c]);var d=r;o.push([0,"chunk-vendors"]),a()})({0:function(e,t,a){e.exports=a("56d7")},"00f0":function(e,t,a){},"05a8":function(e,t,a){},"0c7a":function(e,t,a){},"0cdf":function(e,t,a){"use strict";a("0c7a")},"0daf":function(e,t,a){"use strict";a("05a8")},"142c":function(e,t,a){"use strict";a("1df4")},"1df4":function(e,t,a){},"1f5c":function(e,t,a){"use strict";a("1f8e")},"1f8e":function(e,t,a){},"29cf":function(e,t,a){},4678:function(e,t,a){var n={"./af":"2bfb","./af.js":"2bfb","./ar":"8e73","./ar-dz":"a356","./ar-dz.js":"a356","./ar-kw":"423e","./ar-kw.js":"423e","./ar-ly":"1cfd","./ar-ly.js":"1cfd","./ar-ma":"0a84","./ar-ma.js":"0a84","./ar-sa":"8230","./ar-sa.js":"8230","./ar-tn":"6d83","./ar-tn.js":"6d83","./ar.js":"8e73","./az":"485c","./az.js":"485c","./be":"1fc1","./be.js":"1fc1","./bg":"84aa","./bg.js":"84aa","./bm":"a7fa","./bm.js":"a7fa","./bn":"9043","./bn-bd":"9686","./bn-bd.js":"9686","./bn.js":"9043","./bo":"d26a","./bo.js":"d26a","./br":"6887","./br.js":"6887","./bs":"2554","./bs.js":"2554","./ca":"d716","./ca.js":"d716","./cs":"3c0d","./cs.js":"3c0d","./cv":"03ec","./cv.js":"03ec","./cy":"9797","./cy.js":"9797","./da":"0f14","./da.js":"0f14","./de":"b469","./de-at":"b3eb","./de-at.js":"b3eb","./de-ch":"bb71","./de-ch.js":"bb71","./de.js":"b469","./dv":"598a","./dv.js":"598a","./el":"8d47","./el.js":"8d47","./en-au":"0e6b","./en-au.js":"0e6b","./en-ca":"3886","./en-ca.js":"3886","./en-gb":"39a6","./en-gb.js":"39a6","./en-ie":"e1d3","./en-ie.js":"e1d3","./en-il":"7333","./en-il.js":"7333","./en-in":"ec2e","./en-in.js":"ec2e","./en-nz":"6f50","./en-nz.js":"6f50","./en-sg":"b7e9","./en-sg.js":"b7e9","./eo":"65db","./eo.js":"65db","./es":"898b","./es-do":"0a3c","./es-do.js":"0a3c","./es-mx":"b5b7","./es-mx.js":"b5b7","./es-us":"55c9","./es-us.js":"55c9","./es.js":"898b","./et":"ec18","./et.js":"ec18","./eu":"0ff2","./eu.js":"0ff2","./fa":"8df4","./fa.js":"8df4","./fi":"81e9","./fi.js":"81e9","./fil":"d69a","./fil.js":"d69a","./fo":"0721","./fo.js":"0721","./fr":"9f26","./fr-ca":"d9f8","./fr-ca.js":"d9f8","./fr-ch":"0e49","./fr-ch.js":"0e49","./fr.js":"9f26","./fy":"7118","./fy.js":"7118","./ga":"5120","./ga.js":"5120","./gd":"f6b4","./gd.js":"f6b4","./gl":"8840","./gl.js":"8840","./gom-deva":"aaf2","./gom-deva.js":"aaf2","./gom-latn":"0caa","./gom-latn.js":"0caa","./gu":"e0c5","./gu.js":"e0c5","./he":"c7aa","./he.js":"c7aa","./hi":"dc4d","./hi.js":"dc4d","./hr":"4ba9","./hr.js":"4ba9","./hu":"5b14","./hu.js":"5b14","./hy-am":"d6b6","./hy-am.js":"d6b6","./id":"5038","./id.js":"5038","./is":"0558","./is.js":"0558","./it":"6e98","./it-ch":"6f12","./it-ch.js":"6f12","./it.js":"6e98","./ja":"079e","./ja.js":"079e","./jv":"b540","./jv.js":"b540","./ka":"201b","./ka.js":"201b","./kk":"6d79","./kk.js":"6d79","./km":"e81d","./km.js":"e81d","./kn":"3e92","./kn.js":"3e92","./ko":"22f8","./ko.js":"22f8","./ku":"2421","./ku.js":"2421","./ky":"9609","./ky.js":"9609","./lb":"440c","./lb.js":"440c","./lo":"b29d","./lo.js":"b29d","./lt":"26f9","./lt.js":"26f9","./lv":"b97c","./lv.js":"b97c","./me":"293c","./me.js":"293c","./mi":"688b","./mi.js":"688b","./mk":"6909","./mk.js":"6909","./ml":"02fb","./ml.js":"02fb","./mn":"958b","./mn.js":"958b","./mr":"39bd","./mr.js":"39bd","./ms":"ebe4","./ms-my":"6403","./ms-my.js":"6403","./ms.js":"ebe4","./mt":"1b45","./mt.js":"1b45","./my":"8689","./my.js":"8689","./nb":"6ce3","./nb.js":"6ce3","./ne":"3a39","./ne.js":"3a39","./nl":"facd","./nl-be":"db29","./nl-be.js":"db29","./nl.js":"facd","./nn":"b84c","./nn.js":"b84c","./oc-lnc":"167b","./oc-lnc.js":"167b","./pa-in":"f3ff","./pa-in.js":"f3ff","./pl":"8d57","./pl.js":"8d57","./pt":"f260","./pt-br":"d2d4","./pt-br.js":"d2d4","./pt.js":"f260","./ro":"972c","./ro.js":"972c","./ru":"957c","./ru.js":"957c","./sd":"6784","./sd.js":"6784","./se":"ffff","./se.js":"ffff","./si":"eda5","./si.js":"eda5","./sk":"7be6","./sk.js":"7be6","./sl":"8155","./sl.js":"8155","./sq":"c8f3","./sq.js":"c8f3","./sr":"cf1e","./sr-cyrl":"13e9","./sr-cyrl.js":"13e9","./sr.js":"cf1e","./ss":"52bd","./ss.js":"52bd","./sv":"5fbd","./sv.js":"5fbd","./sw":"74dc","./sw.js":"74dc","./ta":"3de5","./ta.js":"3de5","./te":"5cbb","./te.js":"5cbb","./tet":"576c","./tet.js":"576c","./tg":"3b1b","./tg.js":"3b1b","./th":"10e8","./th.js":"10e8","./tk":"5aff","./tk.js":"5aff","./tl-ph":"0f38","./tl-ph.js":"0f38","./tlh":"cf75","./tlh.js":"cf75","./tr":"0e81","./tr.js":"0e81","./tzl":"cf51","./tzl.js":"cf51","./tzm":"c109","./tzm-latn":"b53d","./tzm-latn.js":"b53d","./tzm.js":"c109","./ug-cn":"6117","./ug-cn.js":"6117","./uk":"ada2","./uk.js":"ada2","./ur":"5294","./ur.js":"5294","./uz":"2e8c","./uz-latn":"010e","./uz-latn.js":"010e","./uz.js":"2e8c","./vi":"2921","./vi.js":"2921","./x-pseudo":"fd7e","./x-pseudo.js":"fd7e","./yo":"7f33","./yo.js":"7f33","./zh-cn":"5c3a","./zh-cn.js":"5c3a","./zh-hk":"49ab","./zh-hk.js":"49ab","./zh-mo":"3a6c","./zh-mo.js":"3a6c","./zh-tw":"90ea","./zh-tw.js":"90ea"};function s(e){var t=o(e);return a(t)}function o(e){if(!a.o(n,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return n[e]}s.keys=function(){return Object.keys(n)},s.resolve=o,e.exports=s,s.id="4678"},"486a":function(e,t,a){},"56d7":function(e,t,a){"use strict";a.r(t);a("e260"),a("e6cf"),a("cca6"),a("a79d");var n=a("7a23");function s(e,t){var a=Object(n["P"])("router-view");return Object(n["G"])(),Object(n["j"])(Object(n["Q"])(this.$route.meta.layout||"div"),null,{default:Object(n["Z"])((function(){return[Object(n["p"])(a)]})),_:1})}a("1f5c");var o=a("6b0d"),i=a.n(o);const l={},r=i()(l,[["render",s]]);var c=r,d=a("6c02"),u={class:"row-12"},b={style:{"text-align":"center",margin:"auto","font-size":"60px"}},h={class:"row-12"},m={style:{"text-align":"center",margin:"auto"}},p=Object(n["o"])("Home"),f=Object(n["o"])("Dataset"),_=Object(n["o"])("Annotation Tool"),g=Object(n["o"])("Explore"),j=Object(n["o"])("Others");function y(e,t,a,s,o,i){var l=Object(n["P"])("a-layout-header"),r=Object(n["P"])("a-menu-item"),c=Object(n["P"])("router-link"),d=Object(n["P"])("a-menu"),y=Object(n["P"])("a-layout-content"),O=Object(n["P"])("a-layout");return Object(n["G"])(),Object(n["j"])(O,{class:"layout"},{default:Object(n["Z"])((function(){return[Object(n["p"])(l,{style:{height:"200px"}},{default:Object(n["Z"])((function(){return[Object(n["m"])("div",null,[Object(n["m"])("div",u,[Object(n["m"])("h1",b,Object(n["S"])(e.projectTitle),1)]),Object(n["m"])("div",h,[Object(n["m"])("h3",m,Object(n["S"])(e.projectSubTitle),1)])])]})),_:1}),Object(n["p"])(y,{style:{background:"#fff"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(d,{theme:"dark",mode:"horizontal",style:{lineHeight:"64px"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(c,{to:{name:"home"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(r,{key:"home"},{default:Object(n["Z"])((function(){return[p]})),_:1})]})),_:1}),Object(n["p"])(c,{to:{name:"dataset"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(r,{key:"dataset"},{default:Object(n["Z"])((function(){return[f]})),_:1})]})),_:1}),Object(n["p"])(c,{to:{name:"annotationTool"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(r,{key:"tool"},{default:Object(n["Z"])((function(){return[_]})),_:1})]})),_:1}),Object(n["p"])(c,{to:{name:"explore"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(r,{key:"explore"},{default:Object(n["Z"])((function(){return[g]})),_:1})]})),_:1}),Object(n["p"])(c,{to:{name:"others"}},{default:Object(n["Z"])((function(){return[Object(n["p"])(r,{key:"others"},{default:Object(n["Z"])((function(){return[j]})),_:1})]})),_:1})]})),_:1}),Object(n["O"])(e.$slots,"default",{},void 0,!0)]})),_:3})]})),_:3})}var O=Object(n["q"])({name:"Layout",components:{},data:function(){return{projectTitle:"HAA4D",projectSubTitle:"Few-Shot Human Atomic Action Recognition via 3D Spatio-Temporal Skeletal Alignment"}},methods:{}});a("0daf");const v=i()(O,[["render",y],["__scopeId","data-v-ffb3c522"]]);var w=v,k=a("ff79"),x=a.n(k),D=function(e){return Object(n["J"])("data-v-64964481"),e=e(),Object(n["H"])(),e},A={align:"left",style:{"margin-top":"50px","margin-left":"100px","margin-right":"100px"}},S=D((function(){return Object(n["m"])("div",null,[Object(n["m"])("h1",{class:"section"},"Abstract"),Object(n["m"])("p",null,[Object(n["o"])(" Human actions involve complex pose variations, and their 2D projections can be highly ambiguous. Thus 3D Spatio-temporal or 4D (i.e., 3D+T) human skeletons, which are "),Object(n["m"])("b",null,"photometric and viewpoint invariant"),Object(n["o"])(", are an excellent alternative to 2D+T skeletons/pixels to improve action recognition accuracy. This paper proposes a "),Object(n["m"])("b",null,"new 4D dataset"),Object(n["o"])(", "),Object(n["m"])("b",null,"HAA4D"),Object(n["o"])(", consisting of more than "),Object(n["m"])("b",null,"3,300 RGB videos"),Object(n["o"])(" in "),Object(n["m"])("b",null,"300 human atomic action classes"),Object(n["o"])(". HAA4D is "),Object(n["m"])("b",null,"clean"),Object(n["o"])(", "),Object(n["m"])("b",null,"diverse"),Object(n["o"])(", "),Object(n["m"])("b",null,"class-balanced"),Object(n["o"])(" where each class is viewpoint-balanced with the use of 4D skeletons, in which as few as one 4D skeleton per class is sufficient for training a deep recognition model. Further, the choice of atomic actions makes annotation even easier because each video clip lasts for only a few seconds. All training and testing 3D skeletons in HAA4D are "),Object(n["m"])("b",null,"globally aligned"),Object(n["o"])(", using a deep alignment model to the same global space, making each skeleton face the "),Object(n["m"])("b",null,"negative z-direction"),Object(n["o"])(". Such alignment makes matching skeletons more stable by "),Object(n["m"])("b",null,"reducing intraclass variations"),Object(n["o"])(" and thus with fewer training samples per class needed for action recognition. Given the high diversity and skeletal alignment in HAA4D, we construct the first baseline "),Object(n["m"])("b",null,"few-shot 4D human atomic action recognition network"),Object(n["o"])(" without bells and whistles, which produces comparable or higher performance than relevant state-of-the-art techniques relying on embedded space encoding without explicit skeletal alignment, using the same small number of training samples of unseen classes. ")]),Object(n["m"])("br"),Object(n["m"])("h1",null,"Our Contribution"),Object(n["m"])("ol",null,[Object(n["m"])("li",null," HAA4D, a human atomic action dataset where all 4D skeletons are globally aligned. HAA4D complements existing prominent 3D+T human action datasets such as NTU-RGB+D and Kinetics Skeleton 400. HAA4D contains 3390 samples of human actions in the wild with 300 different kinds of activities. The samples for each human action range from 2 to 20, each provided with RGB frames and their corresponding 3D skeletons. "),Object(n["m"])("li",null," Introducing an alignment network for predicting orthographic camera poses in the train/test samples, where all 4D skeletons are aligned in the same camera space, each facing the negative z-direction. This allows for better recognition results with a smaller number of training samples compared to ST-GCN, Shift-GCN, and SGN. "),Object(n["m"])("li",null," Introduce the first few-shot baseline for 4D human (atomic) action recognition that produces results comparable to or better than state-of-the-art techniques on unseen classes using a small number of training samples. ")]),Object(n["m"])("br"),Object(n["m"])("div",null,[Object(n["m"])("p",null,[Object(n["o"])(" The 3D skeleton is "),Object(n["m"])("b",null,"viewpoint invariant"),Object(n["o"])(": all train/test 3D skeletons in HAA4D are registered by their respective orthographic camera pose estimated using our global alignment model. Thus a single training 3D skeleton per class is sufficient, in stark contrast to the use of 2D RGB images or skeletons, where a large number of training data is required, and uneven sampling is an issue. "),Object(n["m"])("b",null,"Trained with as few as one 3D+T or 4D burpee skeleton, the network can readily recognize any normalized burpee action shot from any viewing angles"),Object(n["o"])(", including those under the person, which are difficult to capture. As shown in the figure below, we can use the predicted camera poses to rectify views of the input 3D skeletons and bring them to the same coordinate system (globally aligned space). This rectification provides a "),Object(n["m"])("b",null,"stronger correlation between each sample"),Object(n["o"])(" and allows us to utilize the explicit information, such as the coordinate of the joints, directly for sequence matching and obtain a higher accuracy in differentiate the action. ")]),Object(n["m"])("div",{style:{"text-align":"center"}},[Object(n["m"])("img",{src:x.a,alt:"../assets/teaser.png",style:{width:"80%"}})])])],-1)})),T=D((function(){return Object(n["m"])("br",null,null,-1)})),G=[S,T];function z(e,t,a,s,o,i){return Object(n["G"])(),Object(n["l"])("div",A,G)}var I=Object(n["q"])({name:"Home",components:{},data:function(){return{}},methods:{}});a("838a");const H=i()(I,[["render",z],["__scopeId","data-v-64964481"]]);var q=H,P=a("e872"),C=a.n(P),R=a("96e3"),B=a.n(R),F=function(e){return Object(n["J"])("data-v-037ab8c4"),e=e(),Object(n["H"])(),e},Z={align:"left",style:{"margin-top":"50px","margin-left":"100px","margin-right":"100px"}},E=F((function(){return Object(n["m"])("h1",{class:"section"},"HAA4D Dataset",-1)})),N=F((function(){return Object(n["m"])("p",null," HAA4D is a challenging human action recognition 3D+T dataset that is built on top of the HAA500 dataset. HAA500 is a curated video dataset consisting of atomic hu-man action video clips, which provides diversified poseswith variation and examples closer to real-life activities. Similar to Kinetics, the original dataset provides solely in-the-wild RGB videos. However, instead of using existing 2D joints prediction networks, which often produce inaccurate results when joints are hidden or not present, HAA4D consists of hand-labeled 2D human skeletons position. These accurate features can not only increase theprecision of the 3D ground-truth skeleton but also benefit training for new joints prediction models that can reasonably hallucinate out-of-frame joints. The labeled 2D joints will then be raised to 3D using EvoSkeleton. HAA4Dis thus named with its accurate per-frame 3D spatial andtemporal skeletons for human atomic actions. ",-1)})),M=F((function(){return Object(n["m"])("h1",null,"1. Action Classes",-1)})),U={style:{"font-size":"12px",margin:"auto"}},J=F((function(){return Object(n["m"])("br",null,null,-1)})),W={style:{"font-size":"12px",margin:"auto"}},L=F((function(){return Object(n["m"])("br",null,null,-1)})),Y={style:{"font-size":"12px",margin:"auto"}},K=F((function(){return Object(n["m"])("br",null,null,-1)})),V=F((function(){return Object(n["m"])("br",null,null,-1)})),X=F((function(){return Object(n["m"])("h1",null,"2. Dataset Details",-1)})),$=F((function(){return Object(n["m"])("h3",null,"2.1 Comparison with other pubic datasets",-1)})),Q=F((function(){return Object(n["m"])("br",null,null,-1)})),ee=F((function(){return Object(n["m"])("h3",null,"2.2 Dataset Summary",-1)})),te=F((function(){return Object(n["m"])("br",null,null,-1)})),ae=F((function(){return Object(n["m"])("h3",null,"2.3 Evaluation Benchmark",-1)})),ne=F((function(){return Object(n["m"])("p",null," For actions with 20 examples per class, video indexes 0 to 9 are used for training, while videos from 10 to 19 are used for testing. We perform data augmentation on the first ten samples, and among all, videos 8 and 9 are used for validation. For actions that contain only two samples, the one with a smaller index serves as the query, and the other serves as the support. ",-1)})),se=F((function(){return Object(n["m"])("br",null,null,-1)})),oe=F((function(){return Object(n["m"])("br",null,null,-1)})),ie=F((function(){return Object(n["m"])("h1",null,"3. Examples",-1)})),le=Object(n["o"])(" Here we provide some examples in our HAA4D dataset. The image on the left shows the 8-frame sampling from different actions. We use our global alignment model (GAM) to rectify the input skeletons and bring them to the same coordinate system that all actions start at facing the negative z-direction. Some samples of globally aligned skeletons can be seen on the right. More samples can be access in "),re=F((function(){return Object(n["m"])("a",null,"here",-1)})),ce=Object(n["o"])(" . "),de=F((function(){return Object(n["m"])("div",null,[Object(n["m"])("img",{src:C.a,alt:"../assets/8-frames.png",style:{width:"50%"}}),Object(n["m"])("img",{src:B.a,alt:"../assets/example.png",style:{width:"50%"}})],-1)}));function ue(e,t,a,s,o,i){var l=Object(n["P"])("a-table"),r=Object(n["P"])("router-link");return Object(n["G"])(),Object(n["l"])("div",Z,[Object(n["m"])("div",null,[E,N,M,Object(n["m"])("h3",null,"1.1 Twenty examples per class ("+Object(n["S"])(e.jsonData.class_20.length)+")",1),Object(n["m"])("table",null,[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(e.createTable(e.jsonData.class_20),(function(t,a){return Object(n["G"])(),Object(n["l"])("tr",{key:a},[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(t,(function(t){return Object(n["G"])(),Object(n["l"])("td",{key:t},[Object(n["m"])("p",U,Object(n["S"])(e.getIdex(t))+": "+Object(n["S"])(t),1)])})),128))])})),128))]),J,Object(n["m"])("h3",null,"1.2 Two examples per class ("+Object(n["S"])(e.jsonData.class_2.length)+")",1),Object(n["m"])("table",null,[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(e.createTable(e.jsonData.class_2),(function(t,a){return Object(n["G"])(),Object(n["l"])("tr",{key:a},[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(t,(function(t){return Object(n["G"])(),Object(n["l"])("td",{key:t},[Object(n["m"])("p",W,Object(n["S"])(e.getIdex(t))+": "+Object(n["S"])(t),1)])})),128))])})),128))]),L,Object(n["m"])("h3",null," 1.3 Globally Aligned Skeletons ("+Object(n["S"])(e.jsonData.class_global.length)+") ",1),Object(n["m"])("table",null,[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(e.createTable(e.jsonData.class_global),(function(t,a){return Object(n["G"])(),Object(n["l"])("tr",{key:a},[(Object(n["G"])(!0),Object(n["l"])(n["b"],null,Object(n["N"])(t,(function(t){return Object(n["G"])(),Object(n["l"])("td",{key:t},[Object(n["m"])("p",Y,Object(n["S"])(e.getIdex(t))+": "+Object(n["S"])(t),1)])})),128))])})),128))]),K,V,X,$,Object(n["p"])(l,{"data-source":e.datasetComparison,columns:e.datasetComparisonCol,pagination:!1},null,8,["data-source","columns"]),Q,ee,Object(n["p"])(l,{"data-source":e.datasetSummary.data,columns:e.datasetSummary.cols,pagination:!1},null,8,["data-source","columns"]),te,ae,ne,se,oe,ie,Object(n["m"])("p",null,[le,Object(n["p"])(r,{to:{name:"explore"}},{default:Object(n["Z"])((function(){return[re]})),_:1}),ce]),de])])}var be=Object(n["q"])({name:"Home",components:{},data:function(){return{jsonData:null,allClasses:[],num_cols:5,datasetComparisonCol:[{title:"Dataset",dataIndex:"dataset",key:"dataset"},{title:"Samples",dataIndex:"samples",key:"samples"},{title:"Actions",dataIndex:"actions",key:"actions"},{title:"Views",dataIndex:"views",key:"views"},{title:"Modalities",dataIndex:"modalities",key:"modalities"},{title:"Year",dataIndex:"year",key:"year"}],datasetComparison:[{key:1,dataset:"UWA3D Multiview II",samples:1075,actions:30,views:5,modalities:"RGB+D+3DJoints",year:2015},{key:2,dataset:" NTU RGB+D",samples:56880,actions:60,views:80,modalities:"RGB+D+IR+3DJoints",year:2016},{key:3,dataset:"SYSU 3DHOI",samples:480,actions:12,views:1,modalities:"RGB+D+3DJoints",year:2017},{key:4,dataset:"Kinetics 400",samples:306245,actions:400,views:null,modalities:"RGB",year:2017},{key:5,dataset:"NTU RGB+D 120",samples:114480,actions:120,views:155,modalities:"RGB+D+IR+3DJoints",year:2019},{key:6,dataset:"Kinetics-700-2020",samples:633728,actions:700,views:null,modalities:"RGB",year:2020},{key:7,dataset:"Ego4D",samples:3025,actions:110,views:null,modalities:"RGB+3DMeshes+Audio",year:2021},{key:8,dataset:"HAA4D",samples:3390,actions:300,views:"2/20",modalities:"RGB+3DJoints",year:2021}],datasetSummary:{cols:[{title:"Classes",dataIndex:"classes",key:"classes"},{title:"Total Samples",dataIndex:"total_samples",key:"total_samples"},{title:"Globally Aligned Samples",dataIndex:"globally_aligned_samples",key:"globally_aligned_samples"},{title:"Total Frames",dataIndex:"total_frames",key:"total_frames"},{title:"Min Frames",dataIndex:"min_frames",key:"min_frames"},{title:"Max Frames",dataIndex:"max_frames",key:"max_frames"},{title:"Average Frames",dataIndex:"average_frames",key:"average_frames"},{title:"2 Examples",dataIndex:"examples_2",key:"examples_2"},{title:"20 Examples",dataIndex:"examples_20",key:"examples_20"},{title:"Person per Example",dataIndex:"person_per_example",key:"person_per_example"}],data:[{key:1,classes:300,total_samples:3390,globally_aligned_samples:400,total_frames:212042,min_frames:7,max_frames:757,average_frames:63,examples_2:"145 classes",examples_20:"155 classes",person_per_example:1}]}}},methods:{createTable:function(e){for(var t=[],a=[],n=0;n<e.length;n++)a.push(e[n]),((n+1)%this.num_cols===0||n==e.length-1)&&(t.push(a),a=[]);return t},getIdex:function(e){for(var t=0;t<this.allClasses.length;t++)if(this.allClasses[t]===e)return t+1;return-1}},beforeMount:function(){this.jsonData=a("fa9f"),this.allClasses=[];for(var e=0;e<this.jsonData.class_20.length;e++)this.allClasses.push(this.jsonData.class_20[e]);for(var t=0;t<this.jsonData.class_2.length;t++)this.allClasses.push(this.jsonData.class_2[t])}});a("142c");const he=i()(be,[["render",ue],["__scopeId","data-v-037ab8c4"]]);var me=he,pe=a("def7"),fe=a.n(pe),_e=function(e){return Object(n["J"])("data-v-29cf6fec"),e=e(),Object(n["H"])(),e},ge={align:"left",style:{"margin-top":"50px","margin-left":"100px","margin-right":"100px"}},je=_e((function(){return Object(n["m"])("h1",{class:"section"},"Annotation Tool",-1)})),ye=_e((function(){return Object(n["m"])("p",null," To help expand the dataset to more actions and classes, we have developed a simple interactive annotation tool that supports faster user labeling. The annotation tool provides the end-to-end creation of accurate 3D skeletons from 2D images. This page will show the main functionalities of the annotation tool and how to set it up so that we can easily create more distinct action classes through crowdsourcing. ",-1)})),Oe=_e((function(){return Object(n["m"])("br",null,null,-1)})),ve=_e((function(){return Object(n["m"])("h1",null,"Get Started",-1)})),we=_e((function(){return Object(n["m"])("div",{class:"container"},[Object(n["m"])("div",{class:"row"},[Object(n["m"])("div",{class:"col-6"},[Object(n["m"])("ol",null,[Object(n["m"])("li",null,[Object(n["o"])(" Follow the setup instruction in "),Object(n["m"])("a",{href:"https://github.com/Morris88826/HAA_3D-T"},"here"),Object(n["o"])(" to install the annotation tool. ")]),Object(n["m"])("li",null," In the annotating page, (1) shows the annotating canvas. Users can use mouse scroll and drag to move the frame into the wanted position. Click [Reset Zoom] button on the right to go back to the default. "),Object(n["m"])("li",null," To change the frame, use the bar below (2), or press (z) or (x) on your keyboard to go to the prev/next frame. Scroll the bar quickly for a video-like preview. "),Object(n["m"])("li",null," Users can press (3) to load preliminary prediction of the joints from Alphapose. The predicted skeleton will be processed to Evoskeleton format. If the alphapose information doesn't exist, it will run the AlphaPose network to generate the info file (make sure that your device has cuda). "),Object(n["m"])("li",null," To label, you can press [L] on your keyboard to start labeling 17 joints. You can also use your keyboard to label a single joint. keys are [4],[5],[q-u], [a-j],[v]. You can use the image on the right (4) for the guide. "),Object(n["m"])("li",null," The tool supports the linear interpolation method by click (5). Users can simply select the two frames the way, and the tool will perform interpolation for the joints' position in the intermediate frame. "),Object(n["m"])("li",null," Users can monitor the generated 3D joints' position in (7) real-time and correct the corresponding 2D position to increase the accuracy. "),Object(n["m"])("li",null,[Object(n["o"])(" More information can also be found in "),Object(n["m"])("a",{href:"https://github.com/Morris88826/HAA_3D-T"},"here"),Object(n["o"])(". ")])])]),Object(n["m"])("div",{class:"col-6",style:{margin:"auto"}},[Object(n["m"])("img",{src:fe.a,alt:"../assets/annotation_tool.png",style:{width:"100%"}})])])],-1)})),ke=_e((function(){return Object(n["m"])("br",null,null,-1)})),xe=_e((function(){return Object(n["m"])("br",null,null,-1)})),De=_e((function(){return Object(n["m"])("h1",null,"Demo",-1)})),Ae=_e((function(){return Object(n["m"])("p",null,"Here we also provide a demo video for using the annotation tool.",-1)})),Se={style:{"text-align":"center"}},Te={controls:"",style:{width:"100%"}},Ge=["src"],ze=Object(n["o"])(" Your browser does not support the video tag. "),Ie=_e((function(){return Object(n["m"])("br",null,null,-1)})),He=_e((function(){return Object(n["m"])("br",null,null,-1)})),qe=_e((function(){return Object(n["m"])("h1",null,"Further Improvements",-1)})),Pe=_e((function(){return Object(n["m"])("ul",null,[Object(n["m"])("li",null,"Working on the release a web version annotation tool so that users don't need to setup locally."),Object(n["m"])("li",null,"Introduce a better interpolation model.")],-1)}));function Ce(e,t,s,o,i,l){return Object(n["G"])(),Object(n["l"])("div",ge,[Object(n["m"])("div",null,[je,ye,Oe,ve,we,ke,xe,De,Ae,Object(n["m"])("div",Se,[Object(n["m"])("video",Te,[Object(n["m"])("source",{src:a("a304"),type:"video/mp4"},null,8,Ge),ze])]),Ie,He,qe,Pe])])}var Re=Object(n["q"])({name:"AnnotationTool",components:{},data:function(){return{}},methods:{}});a("0cdf");const Be=i()(Re,[["render",Ce],["__scopeId","data-v-29cf6fec"]]);var Fe=Be,Ze=function(e){return Object(n["J"])("data-v-3454a151"),e=e(),Object(n["H"])(),e},Ee={align:"left",style:{"margin-top":"50px","margin-left":"100px","margin-right":"100px"}},Ne=Ze((function(){return Object(n["m"])("h1",{class:"section"},"Explore",-1)})),Me=Object(n["o"])(" Action class: "),Ue={key:0,style:{"margin-top":"20px"}},Je=Object(n["o"])(" Video: "),We=Object(n["o"])("Search");function Le(e,t,a,s,o,i){var l=Object(n["P"])("a-select"),r=Object(n["P"])("a-button"),c=Object(n["P"])("Skeleton3d");return Object(n["G"])(),Object(n["l"])("div",Ee,[Object(n["m"])("div",null,[Ne,Object(n["m"])("div",null,[Me,Object(n["p"])(l,{ref:"select",value:e.class_id,"onUpdate:value":t[0]||(t[0]=function(t){return e.class_id=t}),style:{"min-width":"200px"},options:e.actionOptions,onSelect:e.getVideoOptions},null,8,["value","options","onSelect"])]),null!==e.class_id?(Object(n["G"])(),Object(n["l"])("div",Ue,[Je,Object(n["p"])(l,{ref:"select",value:e.video_id,"onUpdate:value":t[1]||(t[1]=function(t){return e.video_id=t}),style:{"min-width":"200px"},options:e.videoOptions},null,8,["value","options"])])):Object(n["k"])("",!0),null!==e.video_id?(Object(n["G"])(),Object(n["j"])(r,{key:1,type:"primary",style:{"margin-top":"20px"},onClick:e.explore},{default:Object(n["Z"])((function(){return[We]})),_:1},8,["onClick"])):Object(n["k"])("",!0),Object(n["p"])(c,{ref:"skeleton3dRef",visible:e.display,dataPath:e.exploreData,class_id:e.class_id,video_id:e.video_id},null,8,["visible","dataPath","class_id","video_id"])])])}var Ye=a("1da1"),Ke=(a("96cf"),a("7db0"),a("d3b7"),a("4d90"),a("b0c0"),Object(n["m"])("div",{id:"myDiv"},null,-1));function Ve(e,t,a,s,o,i){var l=Object(n["P"])("a-slider");return Object(n["G"])(),Object(n["l"])(n["b"],null,[Ke,e.showSlider?(Object(n["G"])(),Object(n["j"])(l,{key:0,value:e.frame_id,"onUpdate:value":t[0]||(t[0]=function(t){return e.frame_id=t}),"tooltip-visible":!0,min:e.frames.min,max:e.frames.max,onChange:e.changeFrame},null,8,["value","min","max","onChange"])):Object(n["k"])("",!0)],64)}a("ac1f"),a("1276");var Xe=a("4468"),$e=a.n(Xe),Qe=Object(n["q"])({name:"Skeleton3d",props:["visible","dataPath","class_id","video_id"],components:{},data:function(){return{showSlider:!1,frame_id:0,frames:{min:0,max:0},data:[],bones:[[0,1],[1,2],[2,3],[0,4],[4,5],[5,6],[0,7],[7,8],[8,9],[9,10],[8,11],[11,12],[12,13],[8,14],[14,15],[15,16]],joint_name:["lower_spine","right_hip","right_knee","right_ankle","left_hip","left_knee","left_ankle","mid_spine","upper_spine","neck","nose","left_shoulder","left_elbow","left_hand","right_shoulder","right_elbow","right_hand"]}},methods:{createPlot:function(){for(var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:0,t=[],a=this.data[e].data,n=0;n<this.bones.length;n++){var s=this.bones[n][0],o=this.bones[n][1],i=a[s],l=a[o],r={type:"scatter3d",x:[i[0],l[0]],y:[i[1],l[1]],z:[i[2],l[2]],mode:"lines+markers+text",name:"("+this.joint_name[s]+") - ("+this.joint_name[o]+")",text:[this.joint_name[s],this.joint_name[o]],textposition:"top",width:5,marker:{size:5}};t.push(r)}var c={autosize:!1,width:1e3,height:500,font:{size:8},scene:{aspectmode:"manual",aspectratio:{x:1,y:1,z:1},xaxis:{range:[-1,1]},yaxis:{range:[-1,1]},zaxis:{range:[-1,1]},camera:{up:{x:0,y:-1,z:0},eye:{x:0,y:0,z:-2}}}};$e.a.newPlot(document.getElementById("myDiv"),t,c)},_handleData:function(e){for(var t=e.split(","),a=[],n=0;n<t.length;n++)a.push(parseFloat(t[n]));return a},handleData:function(e){var t={class_id:e.class_id,video_id:e.video_id,frame_id:e.frame_id,data:[this._handleData(e.lower_spine),this._handleData(e.right_hip),this._handleData(e.right_knee),this._handleData(e.right_ankle),this._handleData(e.left_hip),this._handleData(e.left_knee),this._handleData(e.left_ankle),this._handleData(e.mid_spine),this._handleData(e.upper_spine),this._handleData(e.neck),this._handleData(e.nose),this._handleData(e.left_shoulder),this._handleData(e.left_elbow),this._handleData(e.left_hand),this._handleData(e.right_shoulder),this._handleData(e.right_elbow),this._handleData(e.right_hand)]};return t},getSkeletons:function(e,t){var a=this;return Object(Ye["a"])(regeneratorRuntime.mark((function n(){return regeneratorRuntime.wrap((function(n){while(1)switch(n.prev=n.next){case 0:return n.abrupt("return",a.axios.post("api/v1/skeletons_3d",{class_id:e,video_id:t}));case 1:case"end":return n.stop()}}),n)})))()},changeFrame:function(){this.createPlot(this.frame_id)},show:function(){var e=this;this.frame_id=0,this.getSkeletons(this.class_id,this.video_id).then((function(t){if(200!==t.status)throw t;e.data=[];for(var a=0;a<t.data.data.length;a++)e.data.push(e.handleData(t.data.data[a]));e.data.length>0&&(document.getElementById("myDiv").style.display="block",e.createPlot(),e.frames={min:0,max:e.data.length},e.showSlider=!0)})).catch((function(e){console.log(e)}))}},mounted:function(){var e=this;Object(n["X"])((function(){return e.visible}),(function(){0==e.visible&&(document.getElementById("myDiv").style.display="none",e.showSlider=!1)}))}});const et=i()(Qe,[["render",Ve]]);var tt=et,at=Object(n["q"])({name:"Explore",components:{Skeleton3d:tt},data:function(){return{class_id:null,video_id:null,actionOptions:[],videoOptions:[],display:!1,exploreData:"../database/skeletons_3d/abseiling/abseiling_000.json"}},methods:{getVideoOptions:function(e){this.video_id=null,this.videoOptions=[],this.display=!1;for(var t=this.actionOptions.find((function(t){return t.value===e})),a=0;a<1;a++)this.videoOptions.push({value:a,label:t.label+"_"+String(a).padStart(3,"0")})},getActionOptions:function(){var e=this;return Object(Ye["a"])(regeneratorRuntime.mark((function t(){return regeneratorRuntime.wrap((function(t){while(1)switch(t.prev=t.next){case 0:return t.next=2,e.axios.get("api/v1/action_classes").then((function(t){if(200!==t.status)throw t;for(var a=0;a<t.data.data.length;a++)e.actionOptions.push({value:t.data.data[a].id,label:t.data.data[a].name})})).catch((function(e){console.log(e)}));case 2:case"end":return t.stop()}}),t)})))()},explore:function(){this.display=!0,this.$refs.skeleton3dRef.show()}},mounted:function(){this.getActionOptions(),this.display=!1}});a("6da4");const nt=i()(at,[["render",Le],["__scopeId","data-v-3454a151"]]);var st=nt,ot={align:"left",style:{"margin-top":"50px","margin-left":"100px","margin-right":"100px"}},it=Object(n["n"])('<div data-v-ccce54b8><h1 class="section" data-v-ccce54b8>Downloads</h1><p data-v-ccce54b8> Detailed information of HAA4D - <a href="https://drive.google.com/file/d/1bmd_rOZ8jR7OS3NRfF7HbDOHHccEFIB7/view?usp=sharing" data-v-ccce54b8>Download</a></p><p data-v-ccce54b8>Please contact us for downloading the whole HAA4D dataset.</p><br data-v-ccce54b8><h1 class="section" data-v-ccce54b8>Training Configuration</h1><p data-v-ccce54b8> For training the global alignment network, we perform data augmentation by sampling camera views from a 3-frequency subdivision icosahedron. This gives us 92 additional training samples per example. Since there are 400 examples in HAA4D that are provided with globally aligned skeletons, with the help of data augmentation, we have 36,800 examples of training our global alignment network. We split all the data into training and validated with a ratio of 0.8 under two settings: <b data-v-ccce54b8>cross-views</b> and <b data-v-ccce54b8>cross-actions</b>. We select 73 views on the icosahedron sphere for cross-views and test the rest 19 views to ensure that our network generates predictions decently while encountering unseen views. We also trained our network on cross-views, i.e., 32 out of the 40 classes, to secure that the model is used to generalize different actions. Here are our training environment and configurations in more details: <br data-v-ccce54b8><br data-v-ccce54b8><b data-v-ccce54b8>GPU: </b> GeForce GTX TITAN X and GeForce GTX 1080 Ti <br data-v-ccce54b8><b data-v-ccce54b8>Epochs: </b> 300 <br data-v-ccce54b8><b data-v-ccce54b8>Batch size: </b> 64 <br data-v-ccce54b8><b data-v-ccce54b8>Optimizer: </b> Adam (starting learning rate: 1e-4, weight decay rate: 1e-6) <br data-v-ccce54b8><b data-v-ccce54b8>Loss weight: </b> 10:1 (rotation loss : reconstruction loss) </p><br data-v-ccce54b8><h1 class="section" data-v-ccce54b8>Limitations</h1><ol data-v-ccce54b8><li data-v-ccce54b8> Our dataset contains only a few samples per class, which is intended for enhancing its scalability and extension (e.g. 1 for train and 1 for test, see our 5-way 1-shot experiments in main paper), as unlike the 2D counterparts, HAA4D&#39;s 3D+T skeletons have more degree of freedom making meaningful data augmentation easy for training on large datasets. In our case, we sample the 3D skeletons from different viewpoints and rotate the skeletons accordingly. We can also use mirroring or combining skeleton samples in the same class to introduce more variation to the dataset. Unlike 2D skeletons that can only have one rotation parameter, the properties of 3D skeletons help better perform data augmentation without breaking the original skeleton structure. </li><li data-v-ccce54b8> Our few-shot skeleton-based action recognition architecture currently supports only single-person actions. To accommodate actions involving more than one person, we can use a similar technique as ST-GCN, which utilizes the two skeletons with the highest confidence score in the sequences. For actions that have only one subject, we assume them to be all zeros. With this, we can modify our architecture so that instead of having the shape of (n_ways, n_shots, n_segments, n_encodings) for explicit skeletons encodings, we add one additional dimension so that the skeletons are in the shape of (n_ways, n_shots, 2, n_segments, n_encodings). We then calculate the distance, respectively. Since there are four skeleton sequences, assuming q_s1, q_s2, s_s1, and s_s2 all with the shape of (1, n_segments, n_encodings), we use the minimum distance between the possible combination {d(q_s1,s_s1) + d(q_s2,s_s2), d(q_s1,s_s2) + d(q_s2,s_s1)}. Therefore, we can make this adjustment for multi-person interaction, and the rest of the architecture can remain unchanged. </li></ol><br data-v-ccce54b8><h1 class="section" data-v-ccce54b8>Contact</h1><p data-v-ccce54b8> Please email <a href="https://morris88826.github.io" data-v-ccce54b8>Mu-Ruei Tseng</a> (<a href="mailto: morris88826@gmail.com" data-v-ccce54b8>morris88826@gmail.com</a>) for any questions. </p></div>',1),lt=[it];function rt(e,t,a,s,o,i){return Object(n["G"])(),Object(n["l"])("div",ot,lt)}var ct=Object(n["q"])({name:"Others",components:{},data:function(){return{}},methods:{}});a("6cee");const dt=i()(ct,[["render",rt],["__scopeId","data-v-ccce54b8"]]);var ut=dt,bt=[{path:"/",name:"home",component:q,meta:{layout:w}},{name:"dataset",path:"/dataset",component:me,meta:{layout:w}},{name:"annotationTool",path:"/annotationTool",component:Fe,meta:{layout:w}},{name:"explore",path:"/explore",component:st,meta:{layout:w}},{name:"others",path:"/others",component:ut,meta:{layout:w}}],ht=Object(d["a"])({history:Object(d["b"])(),routes:bt}),mt=ht,pt=a("f23d"),ft=(a("f9e3"),a("2dd8"),a("202f"),a("bc3a")),_t=a.n(ft),gt=a("130e");_t.a.defaults.baseURL="https://haa4d.herokuapp.com/",Object(n["i"])(c).use(pt["a"]).use(mt).use(gt["a"],_t.a).mount("#app")},"6cee":function(e,t,a){"use strict";a("29cf")},"6da4":function(e,t,a){"use strict";a("486a")},"838a":function(e,t,a){"use strict";a("00f0")},"96e3":function(e,t,a){e.exports=a.p+"img/example.a39fecc8.png"},a304:function(e,t,a){e.exports=a.p+"media/demo.8acef8fc.mp4"},def7:function(e,t,a){e.exports=a.p+"img/annotation_tool.eebcc4eb.png"},e872:function(e,t,a){e.exports=a.p+"img/8-frames.6a753ece.png"},fa9f:function(e){e.exports=JSON.parse('{"class_20":["ALS_IceBucket_Challenge","CPR","abseiling","add_new_car_tire","adjusting_glasses","air_drumming","air_guitar","air_hocky","alligator_wrestling","applauding","applying_cream","archery","arm_wave","arm_wrestling","atlatl_throw","axe_throwing","backflip","backward_roll","badminton_overswing","badminton_serve","badminton_underswing","balancebeam_flip","balancebeam_jump","balancebeam_rotate","balancebeam_spin","balancebeam_walk","bandaging","baseball_bunt","baseball_catch_catcher","baseball_catch_groundball","baseball_pitch","baseball_swing","basketball_dribble","basketball_jabstep","basketball_layup","basketball_pass","basketball_shoot","battle-rope_jumping-jack","battle-rope_power-slam","battle-rope_rainbow","battle-rope_russian-twist","battle-rope_sideplank","battle-rope_snake","battle-rope_wave","beer_pong_throw","bench_dip","bending_back","bowing_waist","brushing_floor","burpee","climb_stair","fish-hunting_hold","floss_dance","gym_squat","jumping_jack","play_accordian","play_bagpipes","play_bangu","play_banjo","play_castanets","play_cello","play_clarinet","play_cornett","play_cymbals","play_diabolo","play_doublebass","play_erhu","play_gong","play_grandpiano","play_guitar","play_handpan","play_harmonica","play_harp","play_hulahoop","play_hulusi","play_kendama","play_leaf-flute","play_lute","play_maracas","play_melodic","play_noseflute","play_ocarina","play_otamatone","play_panpipe","play_piccolo","play_recorder","play_sanxian","play_saw","play_saxophone","play_serpent","play_sheng","play_sitar","play_suona","play_tambourine","play_thereminvox","play_timpani","play_triangle","play_trombone","play_trumpet","play_ukulele","play_viola","play_violin","play_xylophone","play_yangqin","play_yoyo","playing_bass_drum","playing_cajon_drum","playing_conga_drum","playing_nunchucks","playing_rubiks_cube","playing_seesaw","playing_snare_drum","playing_taiko_drum","pottery_wheel","pouring_wine","pull_ups","punching_sandbag","punching_speedbag","push_car","push_wheelchair","push_wheelchair_alone","putting_scarf_on","quadruped_hip-extension","racewalk_walk","read_newspaper","reading_book","rescue_breathing","sandboarding_forward","side_lunge","situp","water_skiing","watering_plants","wear_face_mask","wear_helmet","weightlifting_hang","weightlifting_overhead","weightlifting_stand","whipping","whistle_one_hand","whistle_two_hands","workout_chest-pull","workout_crunch","yawning","yoga_bridge","yoga_cat","yoga_dancer","yoga_firefly","yoga_fish","yoga_gate","yoga_locust","yoga_lotus","yoga_pigeon","yoga_tree","yoga_triangle","yoga_updog"],"class_2":["balloon_animal","base_jumping","baseball_catch_flyball","baseball_run","basketball_dunk","basketball_hookshot","belly_dancing","bike_fall","billiard_hit","blow_gun","blowdrying_hair","blowing_balloon","blowing_glass","blowing_gum","blowing_kisses","blowing_leaf","blowing_nose","bmx_jumping","bmx_riding","bowing_fullbody","bowling","bowls_throw","breakdancing_flare","breakdancing_flip","breakdancing_rotate","breakdancing_support","brushing_hair","brushing_teeth","building_snowman","burping","calfrope_catch","calfrope_rope","calfrope_subdue","canoeing_slalom","canoeing_sprint","card_throw","carrying_with_head","cartwheeling","cast_net","chainsaw_log","chainsaw_tree","chalkboard","chewing_gum","chopping_meat","chopping_wood","cleaning_mirror","remove_car_tire","ride_bike","ride_horse","ride_motorcycle","ride_scooter","riding_elephant","riding_mechanical_bull","rock_balancing","rock_paper_scissors","roller-skating_backward","roller-skating_forward","rolling_snow","rowing_boat","running_in_place","running_on_four","runway_walk","sack_race","salute","screw_car_tire","scuba_diving","shake_cocktail","shaking_head","shaving_beard","shoe_shining","shoot_dance","shooting_handgun","shooting_shotgun","shotput_throw","shoveling_snow","shuffle_dance","skateboard_forward","skateboard_grind","skateboard_jump","ski_backflip","ski_cork","ski_frontflip","ski_jump_land","ski_jump_midair","ski_jump_slide","skydiving","sledgehammer_strike_down","sling","slingshot","smoking_exhale","smoking_inhale","snorkeling","snow_angel","snowboard_jump","snowboard_slide","soccer_dribble","soccer_header","soccer_save","soccer_shoot","soccer_throw","softball_pitch","speed_stack","speedskating_forward","spinning_basketball","spinning_book","spinning_plate","spitting_on_face","split_leap","spraying_wall","sprint_kneel","sprint_run","sprint_start","squash_backhand","squash_forehand","stomping_grapes","stone_skipping","styling_hair","surfing","swimming_backstroke","swimming_breast_stroke","swimming_butterfly_stroke","swimming_freestyle","swinging_axe_on_a_tree","sword_swallowing","taekwondo_high_block","taekwondo_kick","taekwondo_low_block","taekwondo_middle_block","taekwondo_punch","taichi_fan","taking_photo_camera","taking_selfie","talking_megaphone","talking_on_phone","tap_dancing","tennis_backhand","tennis_forehand","tennis_serve","three_legged_race","throw_boomerang","throw_paper-plane","throwing_bouquet","tight-rope_walking","tire_pull","tire_sled"],"class_global":["ALS_IceBucket_Challenge","abseiling","add_new_car_tire","adjusting_glasses","air_drumming","air_guitar","air_hocky","alligator_wrestling","applauding","applying_cream","archery","arm_wave","arm_wrestling","atlatl_throw","axe_throwing","backflip","backward_roll","badminton_overswing","badminton_serve","badminton_underswing","balancebeam_spin","balancebeam_walk","bandaging","baseball_bunt","baseball_catch_groundball","baseball_pitch","baseball_swing","basketball_dribble","basketball_jabstep","basketball_layup","basketball_pass","basketball_shoot","battle-rope_jumping-jack","battle-rope_power-slam","battle-rope_rainbow","battle-rope_russian-twist","battle-rope_sideplank","battle-rope_snake","bench_dip","burpee"]}')},ff79:function(e,t,a){e.exports=a.p+"img/teaser.aaea2d06.png"}});
//# sourceMappingURL=app.cfda3b1e.js.map